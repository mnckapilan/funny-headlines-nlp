Thu Feb 25 21:08:27 2021       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            On   | 00000000:00:07.0 Off |                    0 |
| N/A   41C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

Training model.
| Epoch: 01 | Train Loss: 0.49 | Train MSE: 0.49 | Train RMSE: 0.70 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |
| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 10 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 11 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 13 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 14 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 15 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 16 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 18 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 19 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 20 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| MSE: 0.31 | RMSE: 0.56 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.31465229392051697, RMSE: 0.5609387755393982
Found better hyperparameters...

Training model.
| Epoch: 01 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 10 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 11 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 12 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |
| Epoch: 13 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 14 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 15 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 16 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 17 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 18 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| Epoch: 19 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| Epoch: 20 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| MSE: 0.36 | RMSE: 0.60 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.3592483699321747, RMSE: 0.5993733406066895

Training model.
| Epoch: 01 | Train Loss: 0.48 | Train MSE: 0.48 | Train RMSE: 0.69 |
| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 04 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 05 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 09 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 13 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 15 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 16 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 17 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 18 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 19 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 20 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| MSE: 0.33 | RMSE: 0.57 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.3305451571941376, RMSE: 0.5749305486679077

Training model.
| Epoch: 01 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |
| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 15 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 16 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 19 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 20 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| MSE: 0.35 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.3494647741317749, RMSE: 0.591155469417572

Training model.
| Epoch: 01 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 05 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 07 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 14 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 15 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 16 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 17 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 18 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 19 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 20 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.34051409363746643, RMSE: 0.5835358500480652

Training model.
| Epoch: 01 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 04 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 10 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |
| Epoch: 11 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 12 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 13 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 14 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 15 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.53 |
| Epoch: 16 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 17 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 18 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 19 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| Epoch: 20 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.33816197514533997, RMSE: 0.5815169811248779

Training model.
| Epoch: 01 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 05 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 13 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 14 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 15 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 16 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 17 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 18 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 19 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 20 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.33815136551856995, RMSE: 0.5815078616142273

Training model.
| Epoch: 01 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 16 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 19 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 20 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| MSE: 0.36 | RMSE: 0.60 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.357805997133255, RMSE: 0.5981688499450684

Training model.
| Epoch: 01 | Train Loss: 1.28 | Train MSE: 1.28 | Train RMSE: 1.13 |
| Epoch: 02 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 03 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 04 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 05 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 07 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 08 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 09 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 10 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 11 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |
| Epoch: 12 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 13 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |
| Epoch: 14 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |
| Epoch: 15 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 16 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 17 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 18 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 19 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 20 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| MSE: 0.41 | RMSE: 0.64 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.40538451075553894, RMSE: 0.6366981267929077

Training model.
| Epoch: 01 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 04 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 08 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 10 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 11 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 12 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 13 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 14 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 15 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| Epoch: 16 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| Epoch: 17 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |
| Epoch: 18 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |
| Epoch: 19 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |
| Epoch: 20 | Train Loss: 0.23 | Train MSE: 0.23 | Train RMSE: 0.48 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.3404056131839752, RMSE: 0.5834428668022156

Training model.
| Epoch: 01 | Train Loss: 1.50 | Train MSE: 1.50 | Train RMSE: 1.22 |
| Epoch: 02 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |
| Epoch: 03 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |
| Epoch: 04 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 05 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 06 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 07 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |
| Epoch: 08 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.66 |
| Epoch: 09 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.64 |
| Epoch: 10 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |
| Epoch: 11 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 12 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.65 |
| Epoch: 13 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 14 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.64 |
| Epoch: 15 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 16 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 17 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 18 | Train Loss: 0.48 | Train MSE: 0.48 | Train RMSE: 0.69 |
| Epoch: 19 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |
| Epoch: 20 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| MSE: 0.38 | RMSE: 0.62 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.38256537914276123, RMSE: 0.6185187101364136

Training model.
| Epoch: 01 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 12 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 13 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |
| Epoch: 14 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 15 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 16 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 17 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 18 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 19 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| Epoch: 20 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.3404937982559204, RMSE: 0.5835184454917908

Training model.
| Epoch: 01 | Train Loss: 0.93 | Train MSE: 0.93 | Train RMSE: 0.96 |
| Epoch: 02 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 03 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 04 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |
| Epoch: 05 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.64 |
| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 07 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 08 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 09 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.65 |
| Epoch: 10 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 11 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 12 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |
| Epoch: 13 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 14 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 15 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 16 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 17 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 18 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 19 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 20 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |
| MSE: 0.50 | RMSE: 0.71 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.5048069953918457, RMSE: 0.7104977369308472

Training model.
| Epoch: 01 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 10 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 11 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 12 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 13 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 14 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 15 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 16 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| Epoch: 17 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |
| Epoch: 18 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |
| Epoch: 19 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |
| Epoch: 20 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |
| MSE: 0.34 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.3446159362792969, RMSE: 0.5870400071144104

Training model.
| Epoch: 01 | Train Loss: 1.10 | Train MSE: 1.10 | Train RMSE: 1.05 |
| Epoch: 02 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 03 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |
| Epoch: 04 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 05 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 06 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 07 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.66 |
| Epoch: 08 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 09 | Train Loss: 0.46 | Train MSE: 0.46 | Train RMSE: 0.68 |
| Epoch: 10 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 11 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 12 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.69 |
| Epoch: 13 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 14 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 15 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.65 |
| Epoch: 16 | Train Loss: 0.48 | Train MSE: 0.48 | Train RMSE: 0.69 |
| Epoch: 17 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 18 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.68 |
| Epoch: 19 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 20 | Train Loss: 0.49 | Train MSE: 0.49 | Train RMSE: 0.70 |
| MSE: 0.54 | RMSE: 0.74 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.54425048828125, RMSE: 0.7377333641052246

Training model.
| Epoch: 01 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |
| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 15 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 16 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 18 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 19 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 20 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.34040653705596924, RMSE: 0.5834437012672424

Training model.
| Epoch: 01 | Train Loss: 0.87 | Train MSE: 0.87 | Train RMSE: 0.93 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 11 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 12 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 13 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 15 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 16 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 18 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 19 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 20 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.3355965316295624, RMSE: 0.579306960105896

Training model.
| Epoch: 01 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 16 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 17 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 18 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 19 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 20 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| MSE: 0.33 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.33188387751579285, RMSE: 0.5760936141014099

Training model.
| Epoch: 01 | Train Loss: 0.72 | Train MSE: 0.72 | Train RMSE: 0.85 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |
| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 10 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 11 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 12 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 13 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 15 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 16 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 17 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 18 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 19 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 20 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| MSE: 0.34 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.3427366316318512, RMSE: 0.5854371190071106

Training model.
| Epoch: 01 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 15 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 16 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 17 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 18 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 19 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 20 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |
| MSE: 0.35 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.3494221866130829, RMSE: 0.5911194086074829

Training model.
| Epoch: 01 | Train Loss: 0.74 | Train MSE: 0.74 | Train RMSE: 0.86 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 13 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 15 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 16 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 17 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 18 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 19 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 20 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| MSE: 0.34 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.3408742845058441, RMSE: 0.5838444232940674

Training model.
| Epoch: 01 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 16 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 18 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 19 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |
| Epoch: 20 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| MSE: 0.35 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.346462607383728, RMSE: 0.5886107683181763

Training model.
| Epoch: 01 | Train Loss: 0.79 | Train MSE: 0.79 | Train RMSE: 0.89 |
| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |
| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 15 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 16 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 17 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 18 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 19 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |
| Epoch: 20 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| MSE: 0.35 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.35326409339904785, RMSE: 0.5943602323532104

Training model.
| Epoch: 01 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 16 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 18 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 19 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 20 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| MSE: 0.38 | RMSE: 0.61 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.3764362037181854, RMSE: 0.6135439872741699

Training model.
| Epoch: 01 | Train Loss: 4.02 | Train MSE: 4.02 | Train RMSE: 2.00 |
| Epoch: 02 | Train Loss: 0.50 | Train MSE: 0.50 | Train RMSE: 0.71 |
| Epoch: 03 | Train Loss: 0.50 | Train MSE: 0.50 | Train RMSE: 0.70 |
| Epoch: 04 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.68 |
| Epoch: 05 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |
| Epoch: 06 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.66 |
| Epoch: 07 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 08 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 09 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |
| Epoch: 10 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 11 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |
| Epoch: 12 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 13 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 15 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 16 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 17 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 18 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 19 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 20 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| MSE: 0.35 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.34600746631622314, RMSE: 0.5882239937782288

Training model.
| Epoch: 01 | Train Loss: 0.57 | Train MSE: 0.57 | Train RMSE: 0.76 |
| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 04 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 16 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 19 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 20 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| MSE: 0.34 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.34484779834747314, RMSE: 0.5872374176979065

Training model.
| Epoch: 01 | Train Loss: 4.37 | Train MSE: 4.37 | Train RMSE: 2.09 |
| Epoch: 02 | Train Loss: 0.77 | Train MSE: 0.77 | Train RMSE: 0.88 |
| Epoch: 03 | Train Loss: 0.66 | Train MSE: 0.66 | Train RMSE: 0.81 |
| Epoch: 04 | Train Loss: 0.54 | Train MSE: 0.54 | Train RMSE: 0.73 |
| Epoch: 05 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |
| Epoch: 06 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 07 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 08 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 09 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |
| Epoch: 11 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 15 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 16 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 17 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 18 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 19 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 20 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| MSE: 0.55 | RMSE: 0.74 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.5533763766288757, RMSE: 0.7438927292823792

Training model.
| Epoch: 01 | Train Loss: 0.56 | Train MSE: 0.56 | Train RMSE: 0.75 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 14 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 16 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 17 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 18 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 19 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |
| Epoch: 20 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| MSE: 0.42 | RMSE: 0.64 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.41522496938705444, RMSE: 0.6443794965744019

Training model.
| Epoch: 01 | Train Loss: 2.87 | Train MSE: 2.87 | Train RMSE: 1.69 |
| Epoch: 02 | Train Loss: 0.50 | Train MSE: 0.50 | Train RMSE: 0.71 |
| Epoch: 03 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.68 |
| Epoch: 04 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |
| Epoch: 05 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 06 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 07 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |
| Epoch: 08 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 09 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 10 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 11 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 13 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 15 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |
| Epoch: 16 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 17 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 18 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 19 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 20 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| MSE: 0.34 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.3446882665157318, RMSE: 0.5871015787124634

Training model.
| Epoch: 01 | Train Loss: 0.55 | Train MSE: 0.55 | Train RMSE: 0.74 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |
| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |
| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |
| Epoch: 16 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |
| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |
| Epoch: 19 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| Epoch: 20 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |
| MSE: 0.33 | RMSE: 0.58 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001
MSE: 0.33400189876556396, RMSE: 0.5779289603233337

Training model.
| Epoch: 01 | Train Loss: 2.52 | Train MSE: 2.52 | Train RMSE: 1.59 |
| Epoch: 02 | Train Loss: 0.59 | Train MSE: 0.59 | Train RMSE: 0.77 |
| Epoch: 03 | Train Loss: 0.48 | Train MSE: 0.48 | Train RMSE: 0.69 |
| Epoch: 04 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |
| Epoch: 05 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 07 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 08 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 11 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 12 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 14 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 15 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 16 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |
| Epoch: 17 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |
| Epoch: 18 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |
| Epoch: 19 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |
| Epoch: 20 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |
| MSE: 0.35 | RMSE: 0.59 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01
MSE: 0.3506881892681122, RMSE: 0.5921893119812012

Training model.
| Epoch: 01 | Train Loss: 0.54 | Train MSE: 0.54 | Train RMSE: 0.74 |
| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |
| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |
| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |
| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |
| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |
| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |
| Epoch: 16 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |
| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |
| Epoch: 18 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |
| Epoch: 19 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.53 |
| Epoch: 20 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.53 |
| MSE: 0.36 | RMSE: 0.60 |
Current Hyperparameters:
Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001
MSE: 0.36257678270339966, RMSE: 0.6021434664726257

Best Hyperparameters and Metrics
Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01
MSE: 0.31465229392051697, RMSE: 0.5609387755393982
 23:53:00 up 29 days,  8:09,  2 users,  load average: 2.08, 2.14, 2.16
