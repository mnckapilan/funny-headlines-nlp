{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import codecs\n",
    "from dataloaders import *\n",
    "from processor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/Documents/NLP/CW/funny-headlines/venv/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "# Setting random seed and device\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/task-1/train.csv')\n",
    "test_df = pd.read_csv('data/task-1/dev.csv')\n",
    "\n",
    "training_data = train_df['original']\n",
    "training_edits = train_df['edit']\n",
    "test_data = test_df['original']\n",
    "test_edits = test_df['edit']\n",
    "\n",
    "edited_training = pd.Series(create_edited_sentences(training_data, training_edits))\n",
    "edited_test = pd.Series(create_edited_sentences(test_data, test_edits))\n",
    "\n",
    "# Creating word vectors\n",
    "training_vocab, training_tokenized_corpus = create_vocab(edited_training)\n",
    "test_vocab, test_tokenized_corpus = create_vocab(edited_test)\n",
    "joint_vocab, joint_tokenized_corpus = create_vocab(pd.concat([edited_training, edited_test]))\n",
    "\n",
    "training_grades = train_df['meanGrade']\n",
    "\n",
    "training_vector_sentences = vectorize_sentences(training_tokenized_corpus, joint_vocab)\n",
    "training_dataset = Task1Dataset(training_vector_sentences, training_grades)\n",
    "\n",
    "train_dataset, validation_dataset = dataset_split(training_dataset)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn_padd)\n",
    "\n",
    "glove_tensor = build_embedding_tensor(joint_vocab, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
    "    \"\"\"\n",
    "\n",
    "    sq_error = (output - target)**2\n",
    "\n",
    "    sse = np.sum(sq_error)\n",
    "    mse = np.mean(sq_error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
    "\n",
    "    return sse, mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class FFNN(nn.Module):\n",
    "    def __init__(self, glove_tensor, embedding_dim, vocab_size):\n",
    "        super(FFNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0).from_pretrained(glove_tensor)\n",
    "        # hidden layer\n",
    "        self.fc1 = nn.Linear(embedding_dim, 20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(10, 5)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        # output layer\n",
    "        self.output = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        sentence_lengths = x.ne(0).sum(1, keepdims=True)\n",
    "        averaged = embedded.sum(1) / sentence_lengths\n",
    "        out = self.fc1(averaged)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        out = self.relu3(out)\n",
    "        out = self.output(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "  def __init__(self, glove, vocab_size, embedding_dim, out_channels, window_size, output_dim, dropout):\n",
    "    super(CNN, self).__init__()\n",
    "    \n",
    "    # Create the embedding layer as usual\n",
    "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0).from_pretrained(glove)\n",
    "    \n",
    "    self.conv = nn.Conv2d(\n",
    "      in_channels=1, out_channels=out_channels,\n",
    "      kernel_size=(window_size, embedding_dim))\n",
    "    \n",
    "    # the dropout layer\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # the output layer\n",
    "    self.fc = nn.Linear(out_channels, output_dim)\n",
    "        \n",
    "  def forward(self, x):\n",
    "    # x -> (batch size, max_sent_length)\n",
    "    \n",
    "    embedded = self.embedding(x)\n",
    "    # embedded -> (batch size, max_sent_length, embedding_dim)\n",
    "    \n",
    "    # images have 3 RGB channels \n",
    "    # for the text we add 1 channel\n",
    "    embedded = embedded.unsqueeze(1)\n",
    "    # embedded -> (batch size, 1, max_sent_length, embedding dim)\n",
    "\n",
    "    # Compute the feature maps      \n",
    "    feature_maps = self.conv(embedded)\n",
    "\n",
    "    ##########################################\n",
    "    # Q: What is the shape of `feature_maps` ?\n",
    "    ##########################################\n",
    "    # feature_maps -> (batch_size, out_channels, max_sent_len - window_size + 1, 1)\n",
    "    \n",
    "    feature_maps = feature_maps.squeeze(3)\n",
    "    \n",
    "    ##########################################\n",
    "    # Q: why do we remove 1 dimension here?\n",
    "    ##########################################\n",
    "    # The last dimension is not needed as it is of size 1\n",
    "    \n",
    "    # Apply ReLU\n",
    "    feature_maps = F.relu(feature_maps)\n",
    "    \n",
    "    # Apply the max pooling layer\n",
    "    pooled = F.max_pool1d(feature_maps, feature_maps.shape[2])\n",
    "    \n",
    "    pooled = pooled.squeeze(2)\n",
    "\n",
    "    ####################################\n",
    "    # Q: What is the shape of `pooled` ?\n",
    "    ####################################\n",
    "    # pooled -> (batch_size, out_channels)\n",
    "    \n",
    "    dropped = self.dropout(pooled)\n",
    "    preds = self.fc(dropped)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def eval(data_iter, model):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_sse = 0\n",
    "    pred_all = []\n",
    "    trg_all = []\n",
    "    no_observations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            feature, target = batch\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "            # for RNN:\n",
    "            # model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            # model.hidden = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "            sse, __ = model_performance(pred, trg)\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "            pred_all.extend(pred)\n",
    "            trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 50\n",
    "# model = FFNN(glove_tensor, EMBEDDING_DIM, len(joint_vocab))\n",
    "model = CNN(glove_tensor, len(joint_vocab), EMBEDDING_DIM, 3, 5, 1, 0.2)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "def train(train_loader, validation_loader, model, number_epoch):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "    print(\"Training model.\")\n",
    "    for epoch in range(1, number_epoch+1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        no_observations = 0  # Observations used for training so far\n",
    "        for batch in train_loader:\n",
    "            feature, target = batch\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "            # for RNN:\n",
    "            # model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            # model.hidden = model.init_hidden()\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(predictions, target)\n",
    "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "\n",
    "        valid_loss, valid_mse, __, __ = eval(validation_loader, model)\n",
    "\n",
    "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "        Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 02 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 03 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 05 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.57 |\n",
      "| Epoch: 07 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 08 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.52 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 11 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 12 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 13 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 14 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 15 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.33 | Val. MSE: 0.33 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 16 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 17 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 18 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 19 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 20 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 21 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 22 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 23 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 24 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 25 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 26 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 27 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 28 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 29 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 30 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 31 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 32 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 33 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 34 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 35 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 36 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 37 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 38 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 39 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 40 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 41 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 42 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 43 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 44 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 45 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 46 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 47 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 48 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 49 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 50 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 51 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 52 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 53 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 54 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 55 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 56 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 57 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 58 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 59 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 60 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 61 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 62 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 63 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 64 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 65 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 66 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 67 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 68 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 69 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.58 |\n",
      "| Epoch: 70 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 71 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 72 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 73 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 74 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 75 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 76 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 77 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 78 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 79 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 80 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 81 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 82 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 83 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 84 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 85 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 86 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 87 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 88 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 89 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 90 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 91 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 92 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 93 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 94 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 95 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 96 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 97 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 98 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 99 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 100 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.34 | Val. MSE: 0.34 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 101 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 102 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 103 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 104 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 105 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 106 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 107 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 108 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 109 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 110 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 111 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 112 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 113 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 114 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 115 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 116 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 117 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 118 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 119 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 120 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 121 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 122 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 123 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 124 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 125 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 126 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 127 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 128 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 129 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 130 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 131 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 132 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 133 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 134 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 135 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 136 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 137 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 138 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 139 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 140 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 141 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 142 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 143 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 144 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 145 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 146 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 147 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 148 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 149 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 150 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 151 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 152 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 153 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 154 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 155 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 156 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 157 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 158 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 159 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 160 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 161 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 162 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 163 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 164 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 165 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 166 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 167 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 168 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 169 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 170 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 171 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 172 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 173 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 174 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 175 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 176 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 177 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 178 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 179 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 180 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 181 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 182 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 183 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 184 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 185 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 186 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch: 187 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 188 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 189 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 190 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 191 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 192 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 193 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 194 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 195 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 196 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 197 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.60 |\n",
      "| Epoch: 198 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 199 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.35 | Val. MSE: 0.35 |  Val. RMSE: 0.59 |\n",
      "| Epoch: 200 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |         Val. Loss: 0.36 | Val. MSE: 0.36 |  Val. RMSE: 0.60 |\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, validation_loader, model, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
