{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bearing-daniel"
   },
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMFp_-PwylIW",
    "outputId": "be31abbc-09ea-4799-d614-f1d6f6ccd497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (4.3.3)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.7.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.0)\n",
      "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.58.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2020.11.13)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.13.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.26.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.2)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 16.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.13.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2020.11.13)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from nltk) (4.58.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434678 sha256=dd901835dceebf8d82e68d553f8b20d09e02d66158a520985b600c91bd028bf7\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.5\n",
      "\u001b[33mWARNING: You are using pip version 19.2.1, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "green-hostel"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, random_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from dataloaders import *\n",
    "from processor import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "institutional-burner"
   },
   "outputs": [],
   "source": [
    "# Setting random seed and device\n",
    "SEED = 1\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "4a03d1ae1cd5420685e9532c32c07c28",
      "334613ea43a04a09832b1d00d6c6681d",
      "d61667f407164ff388aa98f5fcf349dc",
      "1e855d87b73649d2bbd8cc60a0882770",
      "d26ccfaca292410c91edc6152c337fc5",
      "038f553c881d49a884ba4dfc47012d7f",
      "ebc880f066194c11ad4d5418519a3d8a",
      "77e42573e2484ef49f99f8ca5ae1a34a"
     ]
    },
    "id": "democratic-letters",
    "outputId": "d7e00e78-7fbb-48a5-98f7-089443456573"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfaf901e299a45cba5bf5810e69d00c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "vocab_size = len(tokenizer.vocab)\n",
    "\n",
    "max_sentence_length = tokenizer.max_model_input_sizes['bert-base-uncased']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "medieval-convertible"
   },
   "outputs": [],
   "source": [
    "def tokenize(corpus):\n",
    "    return [tokenizer.tokenize(sentence) for sentence in corpus]\n",
    "\n",
    "def to_ids(corpus):\n",
    "    return [tokenizer.convert_tokens_to_ids(sentence) for sentence in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "destroyed-internet"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/task-1/train.csv')\n",
    "test_df = pd.read_csv('data/task-1/dev.csv')\n",
    "\n",
    "training_data = train_df['original']\n",
    "training_edits = train_df['edit']\n",
    "test_data = test_df['original']\n",
    "test_edits = test_df['edit']\n",
    "\n",
    "training_grades = train_df['meanGrade']\n",
    "\n",
    "edited_training = pd.Series(create_edited_sentences(training_data, training_edits))\n",
    "edited_test = pd.Series(create_edited_sentences(test_data, test_edits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "apparent-hopkins"
   },
   "outputs": [],
   "source": [
    "training_tokens = tokenize(edited_training)\n",
    "testing_tokens = tokenize(edited_test)\n",
    "\n",
    "training_ids = to_ids(training_tokens)\n",
    "testing_tokens = to_ids(testing_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "informal-protest",
    "outputId": "1d353948-7865-44c9-cb68-984a584c7b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['trump', 'asked', 'du', '##ter', '##te', 'if', 'philippines', 'has', 'death', 'limit', ',', 'philippines', 'ambassador', 'says']\n",
      "[8398, 2356, 4241, 3334, 2618, 2065, 5137, 2038, 2331, 5787, 1010, 5137, 6059, 2758]\n"
     ]
    }
   ],
   "source": [
    "print(training_tokens[100])\n",
    "print(training_ids[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "banned-shepherd"
   },
   "outputs": [],
   "source": [
    "train = Task1Dataset(training_ids, training_grades)\n",
    "train_dataset, validation_dataset = dataset_split(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "practical-creek"
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116,
     "referenced_widgets": [
      "0e768d5983e540518b371f52c99d1025",
      "ec8ed894fbc749c4bfccdd4ee452e78d",
      "2c76979e63f3493cacad46b56707f819",
      "67d478118ab24ec48cf31eb82430eb4f",
      "fadec81086fb4b12b65953d2e8a4a09c",
      "d78d59c0642f4756a52550c109c62f51",
      "c4dcaf8836244b91b942d2426bdbbd8c",
      "54811c3f7b9e42bb9c6c2cf6bdb74fab",
      "99b2a8882135480191ba98e03f47d7e1",
      "6449e9d7b5c24daabd670c91b0e51163",
      "64731e0c48ad4fc3880456b97039f3da",
      "f2894bfbbd1d404ebb9329ec7d80e140",
      "e8b08ba0e699499d8d83ec6b74b2672a",
      "ed70417ed2ea4e60b3059317d0d1c17d",
      "92ce7f01b70043e0bf16344a443ec7d8",
      "564bd78b5d454e15a0f04a6f2fb7f30d"
     ]
    },
    "id": "sorted-tomato",
    "outputId": "182722a0-90d5-4ab9-ed0c-e4841c48facf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a721e0e940134cb6893fb0c742852f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65985c4d4d04497b95dd857d2a27ba0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "searching-winner"
   },
   "outputs": [],
   "source": [
    "class BertGradePredictor(nn.Module):\n",
    "    def __init__(self, bert_model, total_layers, hid_size, out_size, isBidir, drop):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.bert_model = bert_model\n",
    "\n",
    "        self.isBidir = isBidir\n",
    "        \n",
    "        embed_size = bert_model.config.to_dict()['hidden_size']\n",
    "\n",
    "        if total_layers < 3:\n",
    "          drop = 0\n",
    "\n",
    "        hid_output_size = hid_size\n",
    "        if isBidir:\n",
    "          hid_output_size = hid_output_size * 2\n",
    "        \n",
    "        self.drop = drop\n",
    "\n",
    "        self.gru = nn.GRU(input_size=embed_size,\n",
    "                          hidden_size=hid_size,\n",
    "                          num_layers=total_layers,\n",
    "                          bidirectional=isBidir,\n",
    "                          batch_first=True,\n",
    "                          dropout=drop)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hid_output_size, out_size)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        isBidir = self.isBidir\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_embed = self.bert_model(x)\n",
    "            x_embed = x_embed[0]\n",
    "        \n",
    "        cell, hid = self.gru(x_embed)\n",
    "        hid_last = hid[-1,:,:]\n",
    "        hid_snd_last = hid[-2,:,:]\n",
    "        \n",
    "        if isBidir:\n",
    "            hid = F.dropout(torch.cat((hid_snd_last, hid_last), dim=1), self.drop)\n",
    "        else:\n",
    "            hid = F.dropout(hid_last, self.drop)\n",
    "        \n",
    "        out = self.fc1(hid)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IkkZ8FHuui03"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\r\n",
    "learning_rate = 0.001\r\n",
    "total_layers = 3\r\n",
    "hid_size = 128\r\n",
    "out_size = 1\r\n",
    "drop = 0.3\r\n",
    "isBidir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "polyphonic-garlic"
   },
   "outputs": [],
   "source": [
    "def model_performance(output, target, print_output=False):\n",
    "    \"\"\"\n",
    "    Returns SSE and MSE per batch (printing the MSE and the RMSE)\n",
    "    \"\"\"\n",
    "\n",
    "    sq_error = (output - target)**2\n",
    "\n",
    "    sse = np.sum(sq_error)\n",
    "    mse = np.mean(sq_error)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    if print_output:\n",
    "        print(f'| MSE: {mse:.2f} | RMSE: {rmse:.2f} |')\n",
    "\n",
    "    return sse, mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "curious-delhi"
   },
   "outputs": [],
   "source": [
    "def eval(data_iter, model):\n",
    "    \"\"\"\n",
    "    Evaluating model performance on the dev set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    epoch_sse = 0\n",
    "    pred_all = []\n",
    "    trg_all = []\n",
    "    no_observations = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_iter:\n",
    "            feature, target = batch\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "            # for RNN:\n",
    "            # model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            # model.hidden = model.init_hidden()\n",
    "\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            loss = loss_fn(predictions, target)\n",
    "\n",
    "            # We get the mse\n",
    "            pred, trg = predictions.detach().cpu().numpy(), target.detach().cpu().numpy()\n",
    "            sse, __ = model_performance(pred, trg)\n",
    "\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "            pred_all.extend(pred)\n",
    "            trg_all.extend(trg)\n",
    "\n",
    "    return epoch_loss/no_observations, epoch_sse/no_observations, np.array(pred_all), np.array(trg_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "documented-google"
   },
   "outputs": [],
   "source": [
    "def train(train_loader, validation_loader, model, number_epoch):\n",
    "    \"\"\"\n",
    "    Training loop for the model, which calls on eval to evaluate after each epoch\n",
    "    \"\"\"\n",
    "    print(\"Training model.\")\n",
    "    for epoch in range(1, number_epoch+1):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        epoch_sse = 0\n",
    "        no_observations = 0  # Observations used for training so far\n",
    "        for batch in train_loader:\n",
    "            feature, target = batch\n",
    "            feature, target = feature.to(device), target.to(device)\n",
    "            # for RNN:\n",
    "            # model.batch_size = target.shape[0]\n",
    "            no_observations = no_observations + target.shape[0]\n",
    "            # model.hidden = model.init_hidden()\n",
    "            predictions = model(feature).squeeze(1)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(predictions, target)\n",
    "            sse, __ = model_performance(predictions.detach().cpu().numpy(), target.detach().cpu().numpy())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()*target.shape[0]\n",
    "            epoch_sse += sse\n",
    "\n",
    "        # valid_loss, valid_mse, _, _ = eval(validation_loader, model)\n",
    "\n",
    "        # epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "        # print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} | \\\n",
    "        # Val. Loss: {valid_loss:.2f} | Val. MSE: {valid_mse:.2f} |  Val. RMSE: {valid_mse**0.5:.2f} |')\n",
    "\n",
    "        epoch_loss, epoch_mse = epoch_loss / no_observations, epoch_sse / no_observations\n",
    "        print(f'| Epoch: {epoch:02} | Train Loss: {epoch_loss:.2f} | Train MSE: {epoch_mse:.2f} | Train RMSE: {epoch_mse**0.5:.2f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gmJJFpCE_lWI"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\r\n",
    "loss_fn = loss_fn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "acquired-terrorism",
    "outputId": "e655798c-ea59-41b4-c13b-47da8f68276f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.48 | Train MSE: 0.48 | Train RMSE: 0.69 |\n",
      "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 14 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 15 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 16 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 18 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 19 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 20 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| MSE: 0.31 | RMSE: 0.56 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.3135649859905243, RMSE: 0.5599687099456787\n",
      "Found better hyperparameters...\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 11 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 12 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 13 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 14 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 15 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 16 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 17 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 18 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 19 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| Epoch: 20 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| MSE: 0.34 | RMSE: 0.58 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.3383626639842987, RMSE: 0.5816894769668579\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.46 | Train MSE: 0.46 | Train RMSE: 0.68 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 03 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 04 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |\n",
      "| Epoch: 05 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 13 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 15 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 16 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 18 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 19 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 20 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| MSE: 0.32 | RMSE: 0.57 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.32287028431892395, RMSE: 0.5682167410850525\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 15 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 16 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 18 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 19 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 20 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| MSE: 0.36 | RMSE: 0.60 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.36273127794265747, RMSE: 0.6022717356681824\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.49 | Train MSE: 0.49 | Train RMSE: 0.70 |\n",
      "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 05 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 07 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 08 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 15 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 16 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 17 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 18 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 19 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 20 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| MSE: 0.34 | RMSE: 0.58 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.337558776140213, RMSE: 0.5809980630874634\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 11 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |\n",
      "| Epoch: 12 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |\n",
      "| Epoch: 13 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 14 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 15 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 16 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 17 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| Epoch: 18 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| Epoch: 19 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |\n",
      "| Epoch: 20 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.3479020893573761, RMSE: 0.5898322463035583\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.69 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 04 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 05 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 07 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 14 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 15 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 16 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 17 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 18 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 19 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 20 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| MSE: 0.34 | RMSE: 0.58 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.33742284774780273, RMSE: 0.5808811187744141\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 13 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |\n",
      "| Epoch: 16 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 17 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 19 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 20 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| MSE: 0.37 | RMSE: 0.61 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.3689807057380676, RMSE: 0.6074378490447998\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 1.45 | Train MSE: 1.45 | Train RMSE: 1.20 |\n",
      "| Epoch: 02 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.67 |\n",
      "| Epoch: 03 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 04 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 05 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |\n",
      "| Epoch: 06 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 07 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 08 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 09 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 10 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 11 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.64 |\n",
      "| Epoch: 12 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 13 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 14 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 15 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 16 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 17 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |\n",
      "| Epoch: 18 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 19 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 20 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| MSE: 0.38 | RMSE: 0.62 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.3783392310142517, RMSE: 0.6150928735733032\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 11 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 12 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.53 |\n",
      "| Epoch: 13 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 14 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 15 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| Epoch: 16 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 17 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| Epoch: 18 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |\n",
      "| Epoch: 19 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |\n",
      "| Epoch: 20 | Train Loss: 0.23 | Train MSE: 0.23 | Train RMSE: 0.48 |\n",
      "| MSE: 0.40 | RMSE: 0.63 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.4030599594116211, RMSE: 0.6348700523376465\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 1.65 | Train MSE: 1.65 | Train RMSE: 1.28 |\n",
      "| Epoch: 02 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 03 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 04 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 05 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 06 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 07 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 08 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 09 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 10 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |\n",
      "| Epoch: 11 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 12 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.66 |\n",
      "| Epoch: 13 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 14 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 15 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |\n",
      "| Epoch: 16 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 17 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |\n",
      "| Epoch: 18 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |\n",
      "| Epoch: 19 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 20 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| MSE: 0.36 | RMSE: 0.60 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.3629453778266907, RMSE: 0.6024494767189026\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 12 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 13 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |\n",
      "| Epoch: 14 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 15 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 16 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 17 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 18 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 19 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| Epoch: 20 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.3470371663570404, RMSE: 0.5890986323356628\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 1.37 | Train MSE: 1.37 | Train RMSE: 1.17 |\n",
      "| Epoch: 02 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 03 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.66 |\n",
      "| Epoch: 04 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 05 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 06 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 07 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 08 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 09 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 10 | Train Loss: 0.46 | Train MSE: 0.46 | Train RMSE: 0.68 |\n",
      "| Epoch: 11 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 12 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 13 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 14 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 15 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 16 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 17 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 18 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 19 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 20 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.64 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.3508176803588867, RMSE: 0.5922986268997192\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 11 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |\n",
      "| Epoch: 12 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 13 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 14 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 15 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 16 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| Epoch: 17 | Train Loss: 0.25 | Train MSE: 0.25 | Train RMSE: 0.50 |\n",
      "| Epoch: 18 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |\n",
      "| Epoch: 19 | Train Loss: 0.24 | Train MSE: 0.24 | Train RMSE: 0.49 |\n",
      "| Epoch: 20 | Train Loss: 0.23 | Train MSE: 0.23 | Train RMSE: 0.48 |\n",
      "| MSE: 0.40 | RMSE: 0.63 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.40196067094802856, RMSE: 0.6340036988258362\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.94 | Train MSE: 0.94 | Train RMSE: 0.97 |\n",
      "| Epoch: 02 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 03 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.63 |\n",
      "| Epoch: 04 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 05 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 06 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.65 |\n",
      "| Epoch: 07 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 08 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 09 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.68 |\n",
      "| Epoch: 10 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 11 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 12 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |\n",
      "| Epoch: 13 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.68 |\n",
      "| Epoch: 14 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |\n",
      "| Epoch: 15 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.65 |\n",
      "| Epoch: 16 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 17 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |\n",
      "| Epoch: 18 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 19 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 20 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.67 |\n",
      "| MSE: 0.41 | RMSE: 0.64 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.4097983241081238, RMSE: 0.6401548981666565\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 13 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 15 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 16 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 17 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.52 |\n",
      "| Epoch: 19 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 20 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| MSE: 0.43 | RMSE: 0.66 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 64, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.4304217994213104, RMSE: 0.6560654044151306\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.74 | Train MSE: 0.74 | Train RMSE: 0.86 |\n",
      "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 13 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 15 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 16 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 17 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 18 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 19 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 20 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| MSE: 0.32 | RMSE: 0.57 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.32172876596450806, RMSE: 0.567211389541626\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 16 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 17 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 18 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 19 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 20 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| MSE: 0.32 | RMSE: 0.57 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.3249090611934662, RMSE: 0.5700079202651978\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.79 | Train MSE: 0.79 | Train RMSE: 0.89 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 08 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 13 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 14 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 15 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 16 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 18 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 19 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 20 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| MSE: 0.32 | RMSE: 0.57 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.3246460556983948, RMSE: 0.5697771906852722\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.69 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 13 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 14 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 15 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 16 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 17 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 18 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 19 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 20 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| MSE: 0.36 | RMSE: 0.60 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.3640593886375427, RMSE: 0.6033733487129211\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.86 | Train MSE: 0.86 | Train RMSE: 0.93 |\n",
      "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 06 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 07 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 09 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 10 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 15 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 16 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 17 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 18 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 19 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 20 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| MSE: 0.34 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.3439216613769531, RMSE: 0.5864483714103699\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 16 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 17 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 18 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 19 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 20 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| MSE: 0.33 | RMSE: 0.57 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.3272022306919098, RMSE: 0.5720159411430359\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.64 | Train MSE: 0.64 | Train RMSE: 0.80 |\n",
      "| Epoch: 02 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 05 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 06 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 07 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 08 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |\n",
      "| Epoch: 09 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 10 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 11 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 12 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 14 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 15 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 16 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 17 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 18 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 19 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 20 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| MSE: 0.34 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.34355002641677856, RMSE: 0.5861313939094543\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.64 |\n",
      "| Epoch: 02 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 12 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 14 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 16 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 17 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 18 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 19 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 20 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| MSE: 0.44 | RMSE: 0.66 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 64, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.435568243265152, RMSE: 0.6599759459495544\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 3.89 | Train MSE: 3.89 | Train RMSE: 1.97 |\n",
      "| Epoch: 02 | Train Loss: 0.53 | Train MSE: 0.53 | Train RMSE: 0.73 |\n",
      "| Epoch: 03 | Train Loss: 0.51 | Train MSE: 0.51 | Train RMSE: 0.72 |\n",
      "| Epoch: 04 | Train Loss: 0.49 | Train MSE: 0.49 | Train RMSE: 0.70 |\n",
      "| Epoch: 05 | Train Loss: 0.46 | Train MSE: 0.46 | Train RMSE: 0.68 |\n",
      "| Epoch: 06 | Train Loss: 0.44 | Train MSE: 0.44 | Train RMSE: 0.66 |\n",
      "| Epoch: 07 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 08 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 09 | Train Loss: 0.39 | Train MSE: 0.39 | Train RMSE: 0.62 |\n",
      "| Epoch: 10 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 11 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |\n",
      "| Epoch: 12 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 13 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 14 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 15 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 16 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 17 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 18 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 19 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 20 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| MSE: 0.35 | RMSE: 0.60 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.35415205359458923, RMSE: 0.5951067805290222\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.55 | Train MSE: 0.55 | Train RMSE: 0.74 |\n",
      "| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 07 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 16 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 19 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 20 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.3456900417804718, RMSE: 0.5879541039466858\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 3.58 | Train MSE: 3.58 | Train RMSE: 1.89 |\n",
      "| Epoch: 02 | Train Loss: 0.67 | Train MSE: 0.67 | Train RMSE: 0.82 |\n",
      "| Epoch: 03 | Train Loss: 0.56 | Train MSE: 0.56 | Train RMSE: 0.75 |\n",
      "| Epoch: 04 | Train Loss: 0.46 | Train MSE: 0.46 | Train RMSE: 0.68 |\n",
      "| Epoch: 05 | Train Loss: 0.42 | Train MSE: 0.42 | Train RMSE: 0.65 |\n",
      "| Epoch: 06 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.61 |\n",
      "| Epoch: 07 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 08 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 10 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 11 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 12 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 13 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 14 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 15 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 16 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 17 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.60 |\n",
      "| Epoch: 18 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 19 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.60 |\n",
      "| Epoch: 20 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.3462006151676178, RMSE: 0.5883881449699402\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.56 | Train MSE: 0.56 | Train RMSE: 0.75 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 16 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 17 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 18 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 19 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |\n",
      "| Epoch: 20 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 3, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.34540584683418274, RMSE: 0.5877124071121216\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 4.02 | Train MSE: 4.02 | Train RMSE: 2.01 |\n",
      "| Epoch: 02 | Train Loss: 0.48 | Train MSE: 0.48 | Train RMSE: 0.70 |\n",
      "| Epoch: 03 | Train Loss: 0.49 | Train MSE: 0.49 | Train RMSE: 0.70 |\n",
      "| Epoch: 04 | Train Loss: 0.45 | Train MSE: 0.45 | Train RMSE: 0.67 |\n",
      "| Epoch: 05 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.66 |\n",
      "| Epoch: 06 | Train Loss: 0.43 | Train MSE: 0.43 | Train RMSE: 0.65 |\n",
      "| Epoch: 07 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 08 | Train Loss: 0.40 | Train MSE: 0.40 | Train RMSE: 0.63 |\n",
      "| Epoch: 09 | Train Loss: 0.38 | Train MSE: 0.38 | Train RMSE: 0.62 |\n",
      "| Epoch: 10 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 11 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 12 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 13 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 14 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 15 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 16 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 17 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 18 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 19 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 20 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.34525731205940247, RMSE: 0.587585985660553\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.51 | Train MSE: 0.51 | Train RMSE: 0.71 |\n",
      "| Epoch: 02 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 04 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.58 |\n",
      "| Epoch: 06 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 08 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 09 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 10 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 12 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 13 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 14 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 15 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.54 |\n",
      "| Epoch: 16 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 17 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.53 |\n",
      "| Epoch: 18 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| Epoch: 19 | Train Loss: 0.27 | Train MSE: 0.27 | Train RMSE: 0.52 |\n",
      "| Epoch: 20 | Train Loss: 0.26 | Train MSE: 0.26 | Train RMSE: 0.51 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.2, Learning Rate: 0.001\n",
      "MSE: 0.35232478380203247, RMSE: 0.5935695171356201\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 3.12 | Train MSE: 3.12 | Train RMSE: 1.77 |\n",
      "| Epoch: 02 | Train Loss: 0.69 | Train MSE: 0.69 | Train RMSE: 0.83 |\n",
      "| Epoch: 03 | Train Loss: 0.57 | Train MSE: 0.57 | Train RMSE: 0.75 |\n",
      "| Epoch: 04 | Train Loss: 0.47 | Train MSE: 0.47 | Train RMSE: 0.69 |\n",
      "| Epoch: 05 | Train Loss: 0.41 | Train MSE: 0.41 | Train RMSE: 0.64 |\n",
      "| Epoch: 06 | Train Loss: 0.37 | Train MSE: 0.37 | Train RMSE: 0.61 |\n",
      "| Epoch: 07 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 08 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 09 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 10 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 11 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 12 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 13 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 14 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 15 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 16 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 17 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 18 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 19 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| Epoch: 20 | Train Loss: 0.36 | Train MSE: 0.36 | Train RMSE: 0.60 |\n",
      "| MSE: 0.35 | RMSE: 0.59 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.01\n",
      "MSE: 0.35098397731781006, RMSE: 0.5924389958381653\n",
      "\n",
      "Training model.\n",
      "| Epoch: 01 | Train Loss: 0.50 | Train MSE: 0.50 | Train RMSE: 0.71 |\n",
      "| Epoch: 02 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 03 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 04 | Train Loss: 0.35 | Train MSE: 0.35 | Train RMSE: 0.59 |\n",
      "| Epoch: 05 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 06 | Train Loss: 0.34 | Train MSE: 0.34 | Train RMSE: 0.59 |\n",
      "| Epoch: 07 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 08 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 09 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.58 |\n",
      "| Epoch: 10 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 11 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 12 | Train Loss: 0.33 | Train MSE: 0.33 | Train RMSE: 0.57 |\n",
      "| Epoch: 13 | Train Loss: 0.32 | Train MSE: 0.32 | Train RMSE: 0.56 |\n",
      "| Epoch: 14 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 15 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.55 |\n",
      "| Epoch: 16 | Train Loss: 0.31 | Train MSE: 0.31 | Train RMSE: 0.56 |\n",
      "| Epoch: 17 | Train Loss: 0.30 | Train MSE: 0.30 | Train RMSE: 0.55 |\n",
      "| Epoch: 18 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 19 | Train Loss: 0.29 | Train MSE: 0.29 | Train RMSE: 0.54 |\n",
      "| Epoch: 20 | Train Loss: 0.28 | Train MSE: 0.28 | Train RMSE: 0.53 |\n",
      "| MSE: 0.35 | RMSE: 0.60 |\n",
      "Current Hyperparameters:\n",
      "Batch Size: 256, Hidden Size: 256, Total Layers: 5, Dropout: 0.4, Learning Rate: 0.001\n",
      "MSE: 0.3547375202178955, RMSE: 0.5955984592437744\n",
      "\n",
      "Best Hyperparameters and Metrics\n",
      "Batch Size: 64, Hidden Size: 64, Total Layers: 3, Dropout: 0.2, Learning Rate: 0.01\n",
      "MSE: 0.3135649859905243, RMSE: 0.5599687099456787\n"
     ]
    }
   ],
   "source": [
    "total_layers_list = [3, 5]\r\n",
    "hid_size_list = [64, 256]\r\n",
    "drop_list = [0.2, 0.4]\r\n",
    "batch_size_list = [64, 256]\r\n",
    "learning_rates = [0.01, 0.001]\r\n",
    "\r\n",
    "epochs = 20\r\n",
    "best_batch_size = -1\r\n",
    "best_hid_size = -1\r\n",
    "best_total_layers = -1\r\n",
    "best_drop = -1\r\n",
    "best_learning_rate = -1\r\n",
    "best_mse = 10000\r\n",
    "\r\n",
    "\r\n",
    "for batch_size in batch_size_list:\r\n",
    "  for hid_size in hid_size_list:\r\n",
    "    for total_layers in total_layers_list:\r\n",
    "      for drop in drop_list:\r\n",
    "        for learning_rate in learning_rates:\r\n",
    "          train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size, collate_fn=collate_fn_padd)\r\n",
    "          validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, collate_fn=collate_fn_padd)\r\n",
    "\r\n",
    "          model = BertGradePredictor(bert_model,\r\n",
    "                         total_layers,\r\n",
    "                         hid_size,\r\n",
    "                         out_size,\r\n",
    "                         isBidir,\r\n",
    "                         drop)\r\n",
    "\r\n",
    "          model = model.to(device)\r\n",
    "\r\n",
    "          bert_layers = model.named_parameters()\r\n",
    "          bert_layers = [(layer, parameter) for layer, parameter in bert_layers]\r\n",
    "          for i in range(len(bert_layers)):\r\n",
    "              layer_p = bert_layers[i]\r\n",
    "              layer = layer_p[0]\r\n",
    "              p = layer_p[1]\r\n",
    "              if \"bert_model\" in layer:\r\n",
    "                p.requires_grad = False\r\n",
    "\r\n",
    "          optimizer = optim.Adam(model.parameters(), lr=learning_rate)\r\n",
    "\r\n",
    "          train(train_loader, validation_loader, model, epochs)\r\n",
    "\r\n",
    "          _, _, preds, labels = eval(validation_loader, model)\r\n",
    "\r\n",
    "          _, mse = model_performance(preds, labels, print_output=True)\r\n",
    "\r\n",
    "          rmse = np.sqrt(mse)\r\n",
    "\r\n",
    "          print(\"Current Hyperparameters:\")\r\n",
    "          print(\"Batch Size: {}, Hidden Size: {}, Total Layers: {}, Dropout: {}, Learning Rate: {}\".format(batch_size, hid_size, total_layers, drop, learning_rate))\r\n",
    "          print(\"MSE: {}, RMSE: {}\".format(mse, rmse))\r\n",
    "\r\n",
    "          if mse < best_mse:\r\n",
    "            best_mse = mse\r\n",
    "            best_batch_size = batch_size\r\n",
    "            best_hid_size = hid_size\r\n",
    "            best_total_layers = total_layers\r\n",
    "            best_drop = drop\r\n",
    "            best_learning_rate = learning_rate\r\n",
    "            print(\"Found better hyperparameters...\")\r\n",
    "            torch.save(model.state_dict(), \"./bert.pt\")\r\n",
    "            \r\n",
    "          print()\r\n",
    "\r\n",
    "print(\"Best Hyperparameters and Metrics\")\r\n",
    "best_rmse = np.sqrt(best_mse)\r\n",
    "print(\"Batch Size: {}, Hidden Size: {}, Total Layers: {}, Dropout: {}, Learning Rate: {}\".format(best_batch_size, best_hid_size, best_total_layers, best_drop, best_learning_rate))\r\n",
    "print(\"MSE: {}, RMSE: {}\".format(best_mse, best_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9pBMkH3i0Sz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "038f553c881d49a884ba4dfc47012d7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e768d5983e540518b371f52c99d1025": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2c76979e63f3493cacad46b56707f819",
       "IPY_MODEL_67d478118ab24ec48cf31eb82430eb4f"
      ],
      "layout": "IPY_MODEL_ec8ed894fbc749c4bfccdd4ee452e78d"
     }
    },
    "1e855d87b73649d2bbd8cc60a0882770": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_77e42573e2484ef49f99f8ca5ae1a34a",
      "placeholder": "​",
      "style": "IPY_MODEL_ebc880f066194c11ad4d5418519a3d8a",
      "value": " 232k/232k [00:00&lt;00:00, 3.22MB/s]"
     }
    },
    "2c76979e63f3493cacad46b56707f819": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d78d59c0642f4756a52550c109c62f51",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fadec81086fb4b12b65953d2e8a4a09c",
      "value": 433
     }
    },
    "334613ea43a04a09832b1d00d6c6681d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a03d1ae1cd5420685e9532c32c07c28": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d61667f407164ff388aa98f5fcf349dc",
       "IPY_MODEL_1e855d87b73649d2bbd8cc60a0882770"
      ],
      "layout": "IPY_MODEL_334613ea43a04a09832b1d00d6c6681d"
     }
    },
    "54811c3f7b9e42bb9c6c2cf6bdb74fab": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "564bd78b5d454e15a0f04a6f2fb7f30d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6449e9d7b5c24daabd670c91b0e51163": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64731e0c48ad4fc3880456b97039f3da": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed70417ed2ea4e60b3059317d0d1c17d",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8b08ba0e699499d8d83ec6b74b2672a",
      "value": 440473133
     }
    },
    "67d478118ab24ec48cf31eb82430eb4f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54811c3f7b9e42bb9c6c2cf6bdb74fab",
      "placeholder": "​",
      "style": "IPY_MODEL_c4dcaf8836244b91b942d2426bdbbd8c",
      "value": " 433/433 [00:00&lt;00:00, 6.85kB/s]"
     }
    },
    "77e42573e2484ef49f99f8ca5ae1a34a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92ce7f01b70043e0bf16344a443ec7d8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "99b2a8882135480191ba98e03f47d7e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_64731e0c48ad4fc3880456b97039f3da",
       "IPY_MODEL_f2894bfbbd1d404ebb9329ec7d80e140"
      ],
      "layout": "IPY_MODEL_6449e9d7b5c24daabd670c91b0e51163"
     }
    },
    "c4dcaf8836244b91b942d2426bdbbd8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d26ccfaca292410c91edc6152c337fc5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d61667f407164ff388aa98f5fcf349dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_038f553c881d49a884ba4dfc47012d7f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d26ccfaca292410c91edc6152c337fc5",
      "value": 231508
     }
    },
    "d78d59c0642f4756a52550c109c62f51": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8b08ba0e699499d8d83ec6b74b2672a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ebc880f066194c11ad4d5418519a3d8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec8ed894fbc749c4bfccdd4ee452e78d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed70417ed2ea4e60b3059317d0d1c17d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f2894bfbbd1d404ebb9329ec7d80e140": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_564bd78b5d454e15a0f04a6f2fb7f30d",
      "placeholder": "​",
      "style": "IPY_MODEL_92ce7f01b70043e0bf16344a443ec7d8",
      "value": " 440M/440M [00:07&lt;00:00, 56.1MB/s]"
     }
    },
    "fadec81086fb4b12b65953d2e8a4a09c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
